# -*- coding: utf-8 -*-
"""aico.ipynb

Automatically generated by Colab.


"""

# Install dependencies
!pip install --upgrade google-generativeai ultralytics opencv-python-headless

import cv2
import torch
import random
import numpy as np
import google.generativeai as genai  # Correct import
from IPython.display import display, clear_output
from PIL import Image
import matplotlib.pyplot as plt
import warnings
import time
import IPython.display as display
import os
from google.colab import files
uploaded = files.upload()

video_path = next(iter(uploaded))  # Get uploaded video file

# Suppress warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Set up Gemini
GEMINI_API_KEY = "AIzaSyC2oyfZp_vMJZ6wiy1apnOQ3b3Y4vQHyqA"
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('models/gemini-1.5-pro-latest')

formation = "4-3-3"

# Load YOLOv5
try:
    yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', trust_repo=True)
except Exception as e:
    print(f"Error loading YOLOv5: {e}")
    exit()

def gemini_analysis(prompt):
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"Gemini API Error: {e}")
        return ""

def process_frame(frame):
    players, ball = [], None
    results = yolo_model(frame)

    for *xyxy, conf, cls in results.xyxy[0]:
        label = results.names[int(cls)]
        x1, y1, x2, y2 = map(int, xyxy)
        if label == "person":
            players.append((x1, y1, x2, y2))
        elif label == "sports ball":
            ball = (x1, y1, x2, y2)
    return players, ball

def tactical_insight(players, ball):
    description = f"Our team is playing a {formation} formation with {len(players)} players detected."
    description += " The ball is detected." if ball else " The ball is not detected."
    prompt = f"{description} Provide a brief tactical insight."
    analysis = gemini_analysis(prompt)
    print("üîç Tactical Insight:\n", analysis)

def analyze_video_every_30s(video_path, interval_sec=30):
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print("‚ùå Error opening video file.")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration_sec = total_frames / fps

    print(f"üé• Video Duration: {duration_sec:.2f} seconds")

    current_time = 0

    while current_time < duration_sec:
        frame_number = int(current_time * fps)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
        ret, frame = cap.read()

        if not ret:
            print(f"‚ö†Ô∏è Failed to read frame at {current_time:.2f}s")
            break

        players, ball = process_frame(frame)

        # Draw boxes
        for (x1, y1, x2, y2) in players:
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        if ball:
            cv2.rectangle(frame, (ball[0], ball[1]), (ball[2], ball[3]), (0, 0, 255), 2)

        # Show image
        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(img_rgb)
        display.display(img_pil)

        # Show tactical insight
        tactical_insight(players, ball)

        print(f"‚è±Ô∏è Analyzed frame at {current_time:.2f}s")
        current_time += interval_sec
        time.sleep(10)

    cap.release()
analyze_video_every_30s(video_path, interval_sec=30)